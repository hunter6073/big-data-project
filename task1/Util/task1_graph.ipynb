{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# This notebook contains the script needed for generating visual graphics about task 1's data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### frequent itemset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT \t= 'TEXT'\n",
    "INTEGER = 'INTEGER (LONG)'\n",
    "REAL \t= 'REAL'\n",
    "DATE \t= 'DATE/TIME'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Stat:\n",
    "\tdef __init__(self, name):\n",
    "\t\tself.dataset \t= name\n",
    "\t\tself.textCount \t= 0\n",
    "\t\tself.textCols \t= []\n",
    "\t\tself.intCount \t= 0\n",
    "\t\tself.intCols \t= []\n",
    "\t\tself.dateCount \t= 0\n",
    "\t\tself.dateCols \t= []\n",
    "\t\tself.realCount \t= 0\n",
    "\t\tself.realCols \t= []\n",
    "\tdef add(self, t, col):\n",
    "\t\tif t == TEXT:\n",
    "\t\t\tself.textCount += 1\n",
    "\t\t\tself.textCols.append(col)\n",
    "\t\telif t == INTEGER:\n",
    "\t\t\tself.intCount += 1\n",
    "\t\t\tself.intCols.append(col)\n",
    "\t\telif t == REAL:\n",
    "\t\t\tself.realCount += 1\n",
    "\t\t\tself.realCols.append(col)\n",
    "\t\telif t == DATE:\n",
    "\t\t\tself.dateCount += 1\n",
    "\t\t\tself.dateCols.append(col)\n",
    "\tdef get_stats(self):\n",
    "\t\treturn {\n",
    "\t\t\tTEXT: \t\tself.textCount,\n",
    "\t\t\tINTEGER: \tself.intCount,\n",
    "\t\t\tREAL: \t\tself.realCount,\n",
    "\t\t\tDATE: \t\tself.dateCount\n",
    "\t\t}\n",
    "\n",
    "\tdef get_2_itemset(self):\n",
    "\t\tresult = {\n",
    "\t\t\tTEXT + ';' + INTEGER: 0,\n",
    "\t\t\tTEXT + ';' + REAL: \t0,\n",
    "\t\t\tTEXT + ';' + DATE: \t0,\n",
    "\t\t\tINTEGER + ';' + REAL: 0,\n",
    "\t\t\tINTEGER + ';' + DATE: 0,\n",
    "\t\t\tREAL + ';' + DATE: \t0\n",
    "\t\t}\n",
    "\n",
    "\t\tt = {col for col in self.textCols}\n",
    "\t\ti = {col for col in self.intCols}\n",
    "\t\tr = {col for col in self.realCols}\n",
    "\t\td = {col for col in self.dateCols}\n",
    "\t\t\n",
    "\t\tfor col in t:\n",
    "\t\t\tif col in i: result[TEXT + ';' + INTEGER] += 1\n",
    "\t\t\tif col in r: result[TEXT + ';' + REAL] += 1\n",
    "\t\t\tif col in d: result[TEXT + ';' + DATE] += 1\n",
    "\n",
    "\t\tfor col in i:\n",
    "\t\t\tif col in r: result[INTEGER + ';' + REAL] += 1\n",
    "\t\t\tif col in d: result[INTEGER + ';' + DATE] += 1\n",
    "\n",
    "\t\tfor col in r:\n",
    "\t\t\tif col in d: result[REAL + ';' + DATE] += 1\n",
    "\n",
    "\t\treturn result\n",
    "\n",
    "\tdef get_3_itemset(self):\n",
    "\t\tresult = {\n",
    "\t\t\tTEXT + ';' + INTEGER + ';' + REAL: \t0,\n",
    "\t\t\tTEXT + ';' + REAL + ';' + DATE: \t0,\n",
    "\t\t\tTEXT + ';' + INTEGER  + ';' + DATE: 0,\n",
    "\t\t\tINTEGER + ';' + REAL + ';' + DATE: \t0\n",
    "\t\t}\n",
    "\t\tt = {col for col in self.textCols}\n",
    "\t\ti = {col for col in self.intCols}\n",
    "\t\tr = {col for col in self.realCols}\n",
    "\t\td = {col for col in self.dateCols}\n",
    "\n",
    "\t\tfor col in t:\n",
    "\t\t\tif col in i and col in r: result[TEXT + ';' + INTEGER + ';' + REAL] += 1\n",
    "\t\t\tif col in r and col in d: result[TEXT + ';' + REAL + ';' + DATE] += 1\n",
    "\t\t\tif col in i and col in d: result[TEXT + ';' + INTEGER  + ';' + DATE] += 1\n",
    "\t\tfor col in i:\n",
    "\t\t\tif col in r and col in d: result[INTEGER + ';' + REAL + ';' + DATE] += 1\n",
    "\n",
    "\t\treturn result\n",
    "\n",
    "\tdef get_4_itemset(self):\n",
    "\t\tresult = {\n",
    "\t\t\tTEXT + ';' + INTEGER + ';' + REAL + ';' + DATE: \t0,\n",
    "\t\t}\n",
    "\t\tt = {col for col in self.textCols}\n",
    "\t\ti = {col for col in self.intCols}\n",
    "\t\tr = {col for col in self.realCols}\n",
    "\t\td = {col for col in self.dateCols}\n",
    "\n",
    "\t\tfor col in t:\n",
    "\t\t\tif col in i and col in r and col in d: result[TEXT + ';' + INTEGER + ';' + REAL + ';' + DATE] += 1\n",
    "\n",
    "\t\treturn result\n",
    "\n",
    "class State:\n",
    "\tdef __init__(self):\n",
    "\t\tself.datasets = []\n",
    "\n",
    "\tdef add_dataset(self, dataset):\n",
    "\t\tself.datasets.append(dataset)\n",
    "\n",
    "\tdef get_stats(self):\n",
    "\t\tstats = {\n",
    "\t\t\tTEXT: \t\t0,\n",
    "\t\t\tINTEGER: \t0,\n",
    "\t\t\tREAL: \t\t0,\n",
    "\t\t\tDATE: \t\t0\n",
    "\t\t}\n",
    "\t\tfor dataset in self.datasets:\n",
    "\t\t\tstat = dataset.get_stats()\n",
    "\t\t\tstats[TEXT] += stat[TEXT]\n",
    "\t\t\tstats[INTEGER] += stat[INTEGER]\n",
    "\t\t\tstats[REAL] += stat[REAL]\n",
    "\t\t\tstats[DATE] += stat[DATE]\n",
    "\n",
    "\t\treturn stats\n",
    "\n",
    "\tdef get_2_itemset(self):\n",
    "\t\tstats = {\n",
    "\t\t\tTEXT + ';' + INTEGER: 0,\n",
    "\t\t\tTEXT + ';' + REAL: \t0,\n",
    "\t\t\tTEXT + ';' + DATE: \t0,\n",
    "\t\t\tINTEGER + ';' + REAL: 0,\n",
    "\t\t\tINTEGER + ';' + DATE: 0,\n",
    "\t\t\tREAL + ';' + DATE: \t0\n",
    "\t\t}\n",
    "\n",
    "\t\tfor dataset in self.datasets:\n",
    "\t\t\tstat = dataset.get_2_itemset()\n",
    "\t\t\tstats[TEXT + ';' + INTEGER] += stat[TEXT + ';' + INTEGER]\n",
    "\t\t\tstats[TEXT + ';' + REAL] += stat[TEXT + ';' + REAL]\n",
    "\t\t\tstats[TEXT + ';' + DATE] += stat[TEXT + ';' + DATE]\n",
    "\t\t\tstats[INTEGER + ';' + REAL] += stat[INTEGER + ';' + REAL]\n",
    "\t\t\tstats[INTEGER + ';' + DATE] += stat[INTEGER + ';' + DATE]\n",
    "\t\t\tstats[REAL + ';' + DATE] += stat[REAL + ';' + DATE]\n",
    "\n",
    "\t\treturn stats\n",
    "\n",
    "\tdef get_3_itemset(self):\n",
    "\t\tstats = {\n",
    "\t\t\tTEXT + ';' + INTEGER + ';' + REAL: \t0,\n",
    "\t\t\tTEXT + ';' + REAL + ';' + DATE: \t0,\n",
    "\t\t\tTEXT + ';' + INTEGER  + ';' + DATE: 0,\n",
    "\t\t\tINTEGER + ';' + REAL + ';' + DATE: \t0\n",
    "\t\t}\n",
    "\n",
    "\t\tfor dataset in self.datasets:\n",
    "\t\t\tstat = dataset.get_3_itemset()\n",
    "\t\t\tstats[TEXT + ';' + INTEGER + ';' + REAL] += stat[TEXT + ';' + INTEGER + ';' + REAL]\n",
    "\t\t\tstats[TEXT + ';' + REAL + ';' + DATE] += stat[TEXT + ';' + REAL + ';' + DATE]\n",
    "\t\t\tstats[TEXT + ';' + INTEGER  + ';' + DATE] += stat[TEXT + ';' + INTEGER  + ';' + DATE]\n",
    "\t\t\tstats[INTEGER + ';' + REAL + ';' + DATE] += stat[INTEGER + ';' + REAL + ';' + DATE]\n",
    "\n",
    "\t\treturn stats\n",
    "\n",
    "\tdef get_4_itemset(self):\n",
    "\t\tstats = {\n",
    "\t\t\tTEXT + ';' + INTEGER + ';' + REAL + ';' + DATE: 0\n",
    "\t\t}\n",
    "\t\tfor dataset in self.datasets:\n",
    "\t\t\tstat = dataset.get_4_itemset()\n",
    "\t\t\tstats[TEXT + ';' + INTEGER + ';' + REAL + ';' + DATE] += stat[TEXT + ';' + INTEGER + ';' + REAL + ';' + DATE]\n",
    "\n",
    "\t\treturn stats\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the data from raw input generated by task1.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import simplejson as json\n",
    "\n",
    "directory_in_str = '../raw_output'\n",
    "directory = os.fsencode(directory_in_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start gathering data\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: b'../raw_output'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-dd52c1f0b1fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'start gathering data'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfsdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".json\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: b'../raw_output'"
     ]
    }
   ],
   "source": [
    "datasets = []\n",
    "\n",
    "state = State()\n",
    "\n",
    "none_col = 0\n",
    "none_being_most = 0\n",
    "total_col = 0\n",
    "number_column_types = [0, 0, 0, 0]\n",
    "column_name_length = {}\n",
    "times = []\n",
    "longest_file = ''\n",
    "longest_elapsed = 0\n",
    "key_column_candidates_count = 0\n",
    "\n",
    "max_int = 0\n",
    "min_int = 10000000\n",
    "max_date = None\n",
    "min_date = None\n",
    "dates = []\n",
    "max_real = 0\n",
    "min_real = 10000000\n",
    "longest_5_string = []\n",
    "int_mean = []\n",
    "real_mean = []\n",
    "int_std = []\n",
    "real_std = []\n",
    "avg_length = []\n",
    "\n",
    "print('start gathering data')\n",
    "for file in os.listdir(directory):\n",
    "\tfilename = os.fsdecode(file)\n",
    "\tif filename.endswith(\".json\"):\n",
    "\t\twith open(directory_in_str + '/' + filename) as f:\n",
    "\t\t\tobj = json.load(f)\n",
    "\n",
    "\t\t\ttiming = int(obj['time_elapsed'])\n",
    "\t\t\tif timing > longest_elapsed:\n",
    "\t\t\t\tlongest_elapsed = timing\n",
    "\t\t\t\tlongest_file = filename\n",
    "\t\t\ttimes.append(timing)\n",
    "\t\t\t# for each type, how many columns contain that type\n",
    "\t\t\tdataset = Stat(filename.split('.')[0])\n",
    "\n",
    "\t\t\tfor col in obj['columns']:\n",
    "\t\t\t\tif len(obj['columns'][col]['column_name']) not in column_name_length:\n",
    "\t\t\t\t\tcolumn_name_length[len(obj['columns'][col]['column_name'])] = [1, [obj['columns'][col]['column_name']]]\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tcolumn_name_length[len(obj['columns'][col]['column_name'])][0] += 1\n",
    "\t\t\t\t\tcolumn_name_length[len(obj['columns'][col]['column_name'])][1].append(obj['columns'][col]['column_name'])\n",
    "\t\t\t\tfor t in obj['columns'][col]['data_types']:\n",
    "\t\t\t\t\tdataset.add(t['type'], col)\n",
    "\n",
    "\t\t\t\t\tif t['type'] == INTEGER:\n",
    "\t\t\t\t\t\tif t['max_value'] > max_int: max_int = t['max_value']\n",
    "\t\t\t\t\t\tif t['min_value'] < min_int: min_int = t['min_value']\n",
    "\t\t\t\t\t\tint_mean.append(t['mean'])\n",
    "\t\t\t\t\t\tint_std.append(t['stddev'])\n",
    "\t\t\t\t\telif t['type'] == REAL:\n",
    "\t\t\t\t\t\tif t['max_value'] > max_real: max_real = t['max_value']\n",
    "\t\t\t\t\t\tif t['min_value'] < min_real: min_real = t['min_value']\n",
    "\t\t\t\t\t\treal_mean.append(t['mean'])\n",
    "\t\t\t\t\t\treal_std.append(t['stddev'])\n",
    "\t\t\t\t\telif t['type'] == DATE:\n",
    "\t\t\t\t\t\tdates.append(t['max_value'])\n",
    "\t\t\t\t\t\tdates.append(t['min_value'])\n",
    "\t\t\t\t\telif t['type'] == TEXT:\n",
    "\t\t\t\t\t\tlongest_5_string += t['longest_values']\n",
    "\t\t\t\t\t\tlongest_5_string.sort(reverse=True, key=lambda x: len(x))\n",
    "\t\t\t\t\t\tlongest_5_string = longest_5_string[:5]\n",
    "\t\t\t\t\t\tavg_length.append(t['average_length'])\n",
    "\n",
    "\t\t\t\tnumber_column_types[len(obj['columns'][col]['data_types']) - 1] += 1\n",
    "\t\t\t\tif None in obj['columns'][col]['frequent_values']:\n",
    "\t\t\t\t\tif obj['columns'][col]['frequent_values'][0] == None:\n",
    "\t\t\t\t\t\tnone_being_most += 1\n",
    "\t\t\t\t\tnone_col += 1\n",
    "\t\t\t\ttotal_col += 1\n",
    "\n",
    "\t\t\tif len(obj['key_column_candidates']) != 0:\n",
    "\t\t\t\tkey_column_candidates_count += 1\n",
    "\t\t\tstate.add_dataset(dataset)\n",
    "\n",
    "print('finished')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('finish beautified')\n",
    "print('calculating frequent itemsets...')\n",
    "print('frequent 1 itemsets')\n",
    "print(state.get_stats())\n",
    "print('frequent 2 itemsets')\n",
    "print(state.get_2_itemset())\n",
    "print('frequent 3 itemsets')\n",
    "print(state.get_3_itemset())\n",
    "print('frequent 4 itemsets')\n",
    "print(state.get_4_itemset())\n",
    "\n",
    "print(\"NULL # cols being most frequent value:\", none_being_most)\n",
    "print(\"NULL # cols has None as frequent value:\",none_col)\n",
    "print(\"total # cols:\", total_col)\n",
    "print(\"number of columns per number of data types that one column has\\n\", number_column_types)\n",
    "\n",
    "times.sort()\n",
    "starting_time = times[0]\n",
    "window = 50\n",
    "count = 0\n",
    "d = {}\n",
    "\n",
    "for i in range(len(times)):\n",
    "\tcurr_time = times[i]\n",
    "\tif curr_time - starting_time <= window:\n",
    "\t\tcount += 1\n",
    "\telse:\n",
    "\t\td[starting_time] = count\n",
    "\t\tstarting_time = curr_time\n",
    "\t\tcount = 1\n",
    "\n",
    "print(d)\n",
    "\n",
    "count_min = [0] * (60)\n",
    "count_hour = [0] * 9\n",
    "i = 0\n",
    "\n",
    "for m in range(len(count_min)):\n",
    "\tstart_min = m * 60\n",
    "\tend_min = m * 60 + 60\n",
    "\twhile i < len(times):\n",
    "\t\tif start_min <= times[i] <= end_min:\n",
    "\t\t\tcount_min[m] += 1\n",
    "\t\t\ti += 1\n",
    "\t\telse:\n",
    "\t\t\tbreak\n",
    "i = 0\n",
    "count_hour = [0] * 15\n",
    "for h in range(len(count_hour)):\n",
    "\tstart_hour = h * 60 * 60\n",
    "\tend_hour = (h + 1) * 60 * 60\n",
    "\n",
    "\twhile i < len(times):\n",
    "\t\tif start_hour <= times[i] <= end_hour:\n",
    "\t\t\tcount_hour[h] += 1\n",
    "\t\t\ti += 1\n",
    "\t\telse:\n",
    "\t\t\tbreak\n",
    "\n",
    "print(\"longest time elapsed\", longest_elapsed, filename)\n",
    "print(\"key column candidate count\", key_column_candidates_count)\n",
    "\n",
    "max_length = max([key for key in column_name_length])\n",
    "print(\"max column name length:\", max_length, column_name_length[max_length])\n",
    "\n",
    "print(\"global max int:\", max_int)\n",
    "print(\"global min int:\", min_int)\n",
    "print(\"global max real:\", max_real)\n",
    "print(\"global min real:\", min_real)\n",
    "print(\"length of the longest 5 strings\", [len(i) for i in longest_5_string])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph 1 - Time elapsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "fig_size = plt.rcParams[\"figure.figsize\"]\n",
    "fig_size[0] = 8\n",
    "fig_size[1] = 4\n",
    "plt.rcParams[\"figure.figsize\"] = fig_size\n",
    "\n",
    "x = np.array(count_min)\n",
    "# x = x[:60] + [sum(x[60:120]), sum(x[120:180]), sum(x[180:240]), sum(x[240:300]), sum(x[300:])]\n",
    "# objects = tuple([str(i) + 'm' for i in range(1, 61)] + ['1-2h', '2-3h', '3-4h', '4-5h', '5h+'])\n",
    "objects = tuple(['' for i in range(len(x))])\n",
    "y_pos = np.arange(len(objects))\n",
    "\n",
    "plt.bar(y_pos, x, align='center', alpha=0.5)\n",
    "# plt.xticks(y_pos, objects)\n",
    "plt.ylabel('Number of Occurence')\n",
    "plt.xlabel('Time elapsed in minutes')\n",
    "plt.title('Time elapsed: less than 60 mins')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_hour[0] / sum(count_hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_size = plt.rcParams[\"figure.figsize\"]\n",
    "fig_size[0] = 8\n",
    "fig_size[1] = 4\n",
    "plt.rcParams[\"figure.figsize\"] = fig_size\n",
    "x = np.array(count_hour[1:10])\n",
    "# x = x[:60] + [sum(x[60:120]), sum(x[120:180]), sum(x[180:240]), sum(x[240:300]), sum(x[300:])]\n",
    "# objects = tuple([str(i) + 'm' for i in range(1, 61)] + ['1-2h', '2-3h', '3-4h', '4-5h', '5h+'])\n",
    "objects = tuple(['' for i in range(len(x))])\n",
    "y_pos = np.arange(len(objects))\n",
    "\n",
    "plt.bar(y_pos, x, align='center', alpha=0.5)\n",
    "# plt.xticks(y_pos, objects)\n",
    "plt.ylabel('Number of Occurence')\n",
    "plt.xlabel('Time elapsed in hours')\n",
    "plt.title('Time elapsed: more than 1 hour')\n",
    "plt.xticks(np.arange(len(objects)),['1-2h', '2-3h','3-4h','4-5h','5-6h','6-7h','7-8h','8-9h','9+h'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph 2 - Int mean distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(int_mean)\n",
    "val, y  = np.unique(x, return_counts=True) # counting occurrence of each loan\n",
    "\n",
    "fig_size = plt.rcParams[\"figure.figsize\"]\n",
    "fig_size[0] = 12\n",
    "fig_size[1] = 8\n",
    "plt.rcParams[\"figure.figsize\"] = fig_size\n",
    "\n",
    "plt.xlim(-100, 2300)\n",
    "plt.ylim(0, 60)\n",
    "plt.xlabel(\"Int mean\")\n",
    "plt.ylabel(\"Occurence\")\n",
    "plt.title(\"Int Mean vs. Occurence\")\n",
    "plt.scatter(val,y, s=0.1 * y)\n",
    "\n",
    "print(\"largest occurence:\", np.max(y))\n",
    "print(\"The mean with the largest occurence:\", x[np.argmax(y)])\n",
    "print(\"the largest mean:\", np.max(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph 3 - Int STD distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "for i in int_std:\n",
    "    try:\n",
    "        x.append(float(i))\n",
    "    except Exception:\n",
    "        pass\n",
    "    finally:\n",
    "        pass\n",
    "\n",
    "x = np.array(x)\n",
    "\n",
    "val, y  = np.unique(x, return_counts=True) # counting occurrence of each loan\n",
    "\n",
    "plt.xlabel(\"Int STD\")\n",
    "plt.ylabel(\"Occurence\")\n",
    "plt.title(\"Int SD vs. Occurence\")\n",
    "plt.xlim(-10,500)\n",
    "plt.ylim(0,50)\n",
    "plt.scatter(val,y, s=y/5)\n",
    "\n",
    "print(\"largest occurence:\", np.max(y))\n",
    "print(\"The std with the largest occurence:\", x[np.argmax(y)])\n",
    "print(\"The largest std:\", max(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph 4 - Average Text Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = avg_length\n",
    "val, y  = np.unique(np.array(x), return_counts=True) # counting occurrence of each loan\n",
    "\n",
    "fig_size = plt.rcParams[\"figure.figsize\"]\n",
    "fig_size[0] = 12\n",
    "fig_size[1] = 6\n",
    "plt.rcParams[\"figure.figsize\"] = fig_size\n",
    "\n",
    "plt.xlim(0, 100)\n",
    "plt.ylim(0, 130)\n",
    "plt.xlabel(\"Average Text Length\")\n",
    "plt.ylabel(\"Occurence\")\n",
    "plt.title(\"Average Text Lenght vs. Occurence\")\n",
    "plt.scatter(val,y, s = y/4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"greatest occurence:\", val[np.argmax(y)])\n",
    "print(\"text length with the largest occurence\", np.max(y))\n",
    "print(\"longest length:\", np.max(val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph 5 - Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dateutil.parser import parse\n",
    "import pytz\n",
    "x = dates\n",
    "\n",
    "parsed_dates = []\n",
    "for i in x:\n",
    "    try:\n",
    "        parsed_dates.append(parse(i, fuzzy=True))\n",
    "    except Exception:\n",
    "        pass\n",
    "    finally:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(parsed_dates)):\n",
    "    if parsed_dates[i].tzinfo is None:\n",
    "        parsed_dates[i] = pytz.utc.localize(parsed_dates[i])\n",
    "parsed_dates.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"earliest date, longest data\")\n",
    "print(parsed_dates[0], parsed_dates[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val, y  = np.unique(np.array([str(i) for i in parsed_dates]), return_counts=True) # counting occurrence of each loan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "summary = [(parsed_dates[i], y[i]) for i in range(len(y)) if y[i] > 0 and parsed_dates[i] > pytz.utc.localize(datetime.datetime(year=2008, month=1,day=1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = np.array([i[0] for i in summary])\n",
    "dates = np.array([i[1] for i in summary])\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Occurence\")\n",
    "plt.title(\"Date vs Occurence\")\n",
    "plt.scatter(val,dates, s = dates * 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More graphs about stddev can be generated. But I think that would be too redundant."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
