\documentclass[sigconf]{acmart}

%%
%% \BibTeX command to typeset BibTeX logo in the docs
\AtBeginDocument{%
  \providecommand\BibTeX{{%
    \normalfont B\kern-0.5em{\scshape i\kern-0.25em b}\kern-0.8em\TeX}}}

% Rights management information.  This information is sent to you
% when you complete the rights form.  These commands have SAMPLE
% values in them; it is your responsibility as an author to replace
% the commands and values with those provided to you when you
% complete the rights form.
% \setcopyright{acmcopyright}
% \copyrightyear{2019}
% \acmYear{2019}
% \acmDOI{10.1145/1122445.1122456}

% These commands are for a PROCEEDINGS abstract or paper.
% \acmConference[Woodstock '18]{Woodstock '18: ACM Symposium on Neural
%  Gaze Detection}{June 03--05, 2018}{Woodstock, NY}
% \acmBooktitle{Woodstock '18: ACM Symposium on Neural Gaze Detection,
%  June 03--05, 2018, Woodstock, NY}
% \acmPrice{15.00}
% \acmISBN{978-1-4503-XXXX-X/18/06}
\usepackage[margin=0.5in]{geometry}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\begin{document}

%%
%% The "title" command has an optional parameter,
%% allowing the author to define a "short title" to be used in page headers.
\title{Big data final project}

%%
%% The "author" command and its associated commands are used to define
%% the authors and their affiliations.
%% Of note is the shared affiliation of the first two authors, and the
%% "authornote" and "authornotemark" commands
%% used to denote shared contribution to the research.
\author{Hechun Wang}
\email{hw1964@nyu.edu}
\affiliation{%
  \institution{New York University}
  \city{New York}
  \state{NY}
  \postcode{11201}
}

\author{Kaixuan Zhou}
\email{kz1005@nyu.edu}
\affiliation{%
  \institution{New York University}
  \city{New York}
  \state{NY}
  \postcode{11201}
}

\author{Min Yang}
\email{yangmin05235@outlook.com}
\affiliation{%
  \institution{New York University}
  \city{New York}
  \state{NY}
  \postcode{11201}
}




%%
%% The abstract is a short summary of the work to be presented in the
%% article.
\begin{abstract}
This report details the process of 3 tasks to profile a large collection of open datasets from NYC Opendata and derive metadata that can be used for data discovery, querying and identification of data quality problems. The 3 tasks are to perform generic profiling of 1900 tables, perform semantic profiling on 270 tables to create a prediction algorithm for labelling and perform data analysis on 311 complains.
In order to perform the tasks, the following data analysis methods are performed:
\begin{itemize}
\item {\verb|Data cleaning|}: Processing table names, column names and column content before processing
\item {\verb|Data processing|}: Processing large volume data using map-reduce and spark
\item {\verb|Data explanation|}: Aggregate the processed data and explain the result
\end{itemize}
The findings and results of the tasks are presented in the content below. 
\end{abstract}



%%
%% This command processes the author and affiliation and title
%% information and builds the first part of the formatted document.
\maketitle

\section{Introduction}
The motivation for this project is to implement big data processing methodologies on NYC Opendata dataset to profile a large volume of data with great efficiency and accuracy. The following problems are faced in the process:
\begin{itemize}
\item Bad data in values such as invalid characters or bad representation of data(e.g. N/A, Null in a column of numbers)
\item Processing a large volume dataset in a relative short amount of time
\item perform labelling prediction on columns according to the values of the cells in the column
\end{itemize}
The problems stated above are important for data processing because they each generate devastating effects to the whole process. Bad data will render errors in the processing phase and generate bad results. Using local processing instead of cluster processing will never generate the required results in time. And of course the best results are required from any prediction algorithm to align with the actual labels of each column.
The underlying concept to solve each problem are:
\begin{itemize}
\item Replace and clean invalid characters in each column and unify cells with the same type. 
\item Use map-reduce and spark to process the data in parallel and minimum time
\item Use dictionary, regex and other semantic labelling method to generate a reliable prediction model
\end{itemize}
By utilizing the concepts above, we can generate reliable results in minimum time with maximum efficiency. The results given are much better comparing to running them on one or several personal workstations. The results are also human readable and better prone to evaluation and explanation.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% below this line is Task1%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Task1: Generic Profiling}
In this task,  we are to profile the data sets and derive metadata that can be used for data discovery, querying, and identification of data quality problems. For each column, it should be labelled with the following attributes:
\begin{enumerate}
    \item Number of non-empty cells
    \item Number of empty cells
    \item Number of distinct values
    \item Top-5 most frequent value(s)
    \item Data types (a column may contain values belonging to multiple types)
    \begin{enumerate}
        \item INTEGER (LONG)
        \item REAL
        \item DATE/TIME
        \item TEXT
    \end{enumerate}
\end{enumerate}
The output of the labeling process will be a collection of JSON files, which can be found in our GitHub repository under the result folder.
\subsection{Challenges and Optimization}
In this subsection we are going to discuss some challenges we face along the way, and some solutions and optimizations we have applied to tackle the respective challenges.
\subsubsection{Spark and Spark-SQL}
As we finished the initial version of the program, we found out that the program is taking longer than expected. After team member's review, it appears that we are doing a lot of duplicated work. We used a different spark-sql query for a different task without extracting the data needed in common and reduce the cost of computing.
\begin{enumerate}
    \item The total number of cells, the number of empty cells, and the number of not empty cells were counted for every column in the same dataset.
    \item When we were to find the number of distinct values and top-5 most frequent values, we have two queries for them, and those two queries are doing some duplicated work.
\end{enumerate}
As a solution to optimize:
\begin{enumerate}
    \item We only count the number of rows for one dataset once, and we count the number of non-empty rows for each column. Then, with a simple subtraction, we get the number of empty rows.
    \item We perform a groupby operation. While we are looking for the number of distinct values, we can also maintain the number of occurrence for each distinct value. We can then perform a sortby opeartion to find the top-5 most frequent values.
    \item We change the code from pyspark-sql to pyspark so that it's easy to read and maintain since pyspark-sql query is genrally longer.
\end{enumerate}
\subsubsection{Ways to initiate a spark job}
As our first approach, A bash script was used to submit one pyspark job per dataset. As we collect the data, we realize that for each submitted work, it takes around 60 - 120 seconds to set up the spark context, and it's even longer when Dumbo is under a high usage. 
We then used a nested for loop inside the python script to iterate through all the dataset and all the columns in each dataset.
\subsubsection{Long time to profile the data}
We seperate the task into three portions, and each team member runs one third of the entire task. We maintain a task bank which contains all the task each team member needs to run for TASK 1. We also realized that after a certain time without I/O, dumbo will terminate the session automatically. To handle that, an output indicating which stage of the task is on right now will be printed out after a certain amount of time.erkler
\subsubsection{Fault tolerance}
While we are running the code, we sometimes need to update the script to encounter some unforeseen errors. In order to not rerun the already profiled dataset, we will remove the task from the task bank.
\subsubsection{Miss-classification of "DATE/TIME"}
We are using a package "dateutil.parser" to parse the column value if the default type given by spark is string. However, we decided to detect if it's an INTEGER first, then REAL, then DATE/TIME, and finally TEXT. That leads to some situations when:
\begin{enumerate}
    \item If the given string is "20191209", our type checker would determine this as an INTEGER, rather than a date.
    \item The parser will also classify string looks like "140ST" as "0140-12-05 00:00:00". However, the team didn't notice this issue until 80\% of the data sets are already profiled. This can be solved by manually looking at the co-occured datatype. If DATE/TIME co-occurs with TEXT and INT, that could mean the input data is not problematic.
\end{enumerate}
We treat these as our features. However, because of the ignorance of the above situations, the json output will have the largest DATE and the lowest DATE value being the parsed "DATETIME" object rather than the original string stored in the database. This output format was fixed soon after the team realized the defect, and the codebase is already updated. However, the output gathered previously was not updated due to time limit (the team didn't rerun the code for the profiled datasets).
\subsection{Data Quality Issues}
In this subsection, we will discuss some data quality issues that the project team faced while profiling the data.
\subsubsection{Too many empty and wrong values} Among the x\% columns of the 1900 datasets. x\% of those have NULL being the top-5 most frequent values, and x\% of those have NULL as most frequent value. There are also a lot of "wrong" values. For example, a "Y...." in a column containing some color information, and a 2 digit zip code.
\begin{figure}[htp]
    \centering
    \includegraphics[width=8.5cm]{null_col.png}
    \caption{Column Distribution}
    \label{fig:galaxy}
\end{figure}
\subsubsection{heterogeneous Columns} The graph shows the number of data type that one column has v.s. the count.
\begin{figure}[htp]
    \centering
    \includegraphics[width=7cm]{col_types.png}
    \caption{Column Data Types Distribution}
    \label{fig:galaxy}
\end{figure}
\subsubsection{Miss-classification of "DATE/TIME"} Follow up on heterogeneous columns: Referring to the previous section, the reason why our type chcker miss clasified the data is because the data is not entered in a unified way, and actually we cannot tell if "18880101" is a datetime or some random number; and "2019/04" is a datetime or not unless we look at the column name, or the other values in the column in general.
\subsubsection{Redundant Column Name} The dataset also contains some super long column names. The longest column names contain 161 characters, and they are:
\begin{enumerate}
    \item 'B35 Posting or distributing literature or material containing a threat of violence, injury or harm (including posting such material on the Internet) (D-I only) R'
    \item 'B35 Posting or distributing literature or material containing a threat of violence, injury or harm (including posting such material on the Internet) (D-I only) P'
    \item 'B35 Posting or distributing literature or material containing a threat of violence, injury or harm (including posting such material on the Internet) (D-I only) S'
\end{enumerate}
For these three, the only difference in the naming is the last character. And there are a lot of other redundant column naming as well.
\subsection{Data Exploration and Visualization}
\subsubsection{Time needed to profile the datasets}
\begin{figure}[htp]
    \centering
    \includegraphics[width=8.5cm]{time_elapsed.png}
    \caption{Time Elapsed}
    \label{fig:galaxy}
\end{figure}
Figure 3 only shows the time needed for those files that took less than 30 minutes to process. We can clearly see that the majority of the datasets takes less than 10 minutes to process. There are 15, 21, 20, 11, 19, 11 files that took 30-60 mins, 1-2 hour, 2-3 hour, 3-4 hour, 4-5 hour, and 5-6 hour to process respectively. In the dataset, the dataset that takes the longest to process is "mmvm-mvi3". It takes around 5.8 hour to process.
\subsubsection{Extra Credit: Key column candidate} The team took a naive approach to identify the key column candidate: If a column has number of distinct values equal to the total number of rows of the dataset, then this column is one of the key column candidate. This approach doesn't consider the situation when a composite key is allowed. That is, this approach can only handle the situation when there is one primary key. With this naive approach, the team found out that 533 dataset has a primary key potentially.
\subsubsection{Detailed data report} In this subsection, we are going to discuss the general data layout for the datasets. For the four different data types: INT, REAL, DATE, and TEXT, the global max and min are:
\begin{enumerate}
    \item INT: \textasciitilde$10^{100}, -14248677237$
    \item REAL: inf, -469079690.9
    \item DATE: 0001-01-01, 9999-12-31
    \item len(TEXT): 32759, 1
\end{enumerate}
\begin{figure}[htp]
    \centering
    \includegraphics[width=8.5cm]{int_mean.png}
    \caption{INTEGER (LONG) MEAN DISTRIBUTION}
    \label{fig:galaxy}
\end{figure}
\begin{figure}[htp]
    \centering
    \includegraphics[width=8.5cm]{dates_distribution.png}
    \caption{DATES DISTRIBUTION}
    \label{fig:galaxy}
\end{figure}
\begin{figure}[htp]
    \centering
    \includegraphics[width=8.5cm]{avg_text_length.png}
    \caption{AVERAGE TEXT LENGTH}
    \label{fig:galaxy}
\end{figure}
For simplicity, we only show the significant data rather than the entire dataset. For DATES DISTRIBUTION, we only showed the dates that occur later than year 2008. For INTERGER MEAN DISTRIBUTION, we only show the means that is from the range (-50, 3000), and for better visualization, we only limit the y range as well. So does AVERAGE TEXT LENGTH.
From the graphs, we can see that there are two peaks in the interger mean distribution. One is near 0, and the other one is near 2000. We can also tell that most of the dates are around 2014. And the majority of the average length are less than 25. There are 3028 columns with type TEXT have an average length of 1.
\subsubsection{Frequent itemset analysis}
In the section, we found the 2,3,4-frequent itemsets from the generated metadata. Noticed that it might have some errors according to the previous two sections. Given a support of xxx, and a confidence of xxx, the frequent itemsets are: ;
Thus we can conclude that x, x, and x co-occurs the most
\begin{table}
  \caption{Frequent Itemset}
  \label{tab:freq}
  \begin{tabular}{{l l}}
    \toprule
    Data Types& Support\\
    \midrule
    A: Text& num\\
    B: Integer (long)& num\\
    C: Real& num \\
    D: Date/Time& num\\
    \midrule
    A \& B& num\\
    A \& C& num\\
    A \& D& num\\
    B \& C& num\\
    B \& D& num\\
    C \& D& num\\
    \midrule
    A \& B \& C& num\\
    A \& C \& D& num\\
    B \& C \& D& num\\
    \midrule
    A \& B \& C \& D& num\\
  \bottomrule
\end{tabular}
\end{table}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% below this line is Task2%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Task2: Semantic Profiling}
In this task, we are to extract detailed information about the semantics for 270 given columns. For each column, it should be labelled with one or more of the following labels:
\begin{itemize}
\item Person name
\item Business name
\item Phone Number
\item Address
\item Street name
\item City
\item Neighborhood
\item LAT/LON coordinates
\item Zip code
\item Borough
\item School name
\item Color
\item Car make
\item City agency
\item Areas of study
\item Subjects in school
\item School Levels
\item College/University names
\item Websites
\item Building Classification
\item Vehicle Type
\item Type of location
\item Parks/Playgrounds
\item Other
\end{itemize}
After labelling, it is required for each semantic type identified, all the values encountered for that type are to be enumerated and presented in an aggregated collection. The output for this section can be found in our GitHub repository under the result folder.
\subsection{Preparations}
Before starting on the prediction model, the first step that must be taken is to label all the columns given by hand. The process to do this can be split into 3 steps:
\begin{itemize}
\item assigning each column with 1 label(most cases)
\item go through the column to find cells with different labels than the one labeled
\item cross identification by exchanging columns between different group members
\end{itemize}
\subsection{Strategies}
There are 3 strategies used in performing this section's task:
\begin{itemize}
\item Regex identification
\item column name dictionary identification
\item mixed identification
\end{itemize}
And each can be detailed in the following fashion:
\subsubsection{Regex identification}
This identification strategy is mainly used for detecting phone numbers, zip codes and Lat/Lon coordinates. Which are columns that contain values with strict formatting and can be identified using regular expression matching very easily. This identification strategy is performed using the following steps:
\begin{itemize}
\item Percolate the column and get the value of each cell
\item Use the value gotten from each cell and match the value to a specific regular expression type as phone number, zip codes and Lat/Lon coordinates and see if it gets a match  
\item If there is a match, we can assign the matching label to the column
\end{itemize}
\subsubsection{column name dictionary identification}
This identification strategy is mainly used for detecting columns with values that are not strictly formatted nor is small enough to use dictionary method on each cell's value. During the labelling stage, we discovered that most of the columns given contain a certain keyword within it's column name that could directly point to the main label of the column. For example table column \verb|2bnn-yakx_Vehicle_Color| contains the keyword color which can be used to directly label this column. This works for most columns given and can be done in the following steps:
\begin{itemize}
\item Design the dictionary of keywords that match to labels. For example "boro" is a match for the label "Borough"
\item Go through the columns assigned to us and clean the column name, turning every letter into lower case and removing any invalid characters apart from [a-z] and [0-9]
\item percolate the dictionary of keywords and check if each keyword are contained within the dictionary, if it is contained within the dictionary, assign the label to the column
\end{itemize}
\subsubsection{mixed identification}
By merging the two identification strategies together, we are able to perform an identification strategy that generates better result, the mixed identification process is relatively simple:
\begin{itemize}
\item Perform the column name dictionary identification on a column, and put any detected label into a predicted list
\item Go through the content of the column, and use regex identification on each of the cells and generate, if any labels that matches the regular expression.
\item For those columns that have no labels from the identifications combined, we assign a "Other" label to the column
\end{itemize}
\subsection{Benefits and limitations}
The benefits and limitations to the 3 different strategies are very clearly distinguished. For the Regex matching identification method, the benefits are that it could generate an almost 100\% accuracy for any cells containing formatted values. 
For the column name dictionary identification strategy, it would generate a very satisfying result for the columns that contain values with type string and unable to match regex or dictionary due to the large pool of distinct data they contain.
The limitations for each of the two strategies are that they can't perform task that the other could, making them two separate strategies that have to be combined together to get the whole picture. Another limitation of the two is that they can't generate multiple labels for a column individually.
To fix the limitations mentioned above, we merged them together into a mixed strategy that overcomes the limitations and can perform high accuracy detection of labels and able to generate multiple labels for one column to deliver the most satisfying result.
\subsection{Evaluation}
For each strategy, the precision and recall are:

\begin{figure}[htp]
    \centering
    \includegraphics[width=8cm]{ST2.png}
    \caption{result from Regex identification}
    \label{fig:galaxy}
\end{figure}
\begin{figure}[htp]
    \centering
    \includegraphics[width=8cm]{ST1-1.png}
    \caption{result from dictionary identification}
    \label{fig:galaxy}
\end{figure}
\begin{figure}[htp]
    \centering
    \includegraphics[width=8cm]{ST1-2.png}
    \caption{result from dictionary identification cont}
    \label{fig:galaxy}
\end{figure}
\begin{figure}[htp]
    \centering
    \includegraphics[width=8cm]{ST2-1.png}
    \caption{result from mixed identification}
    \label{fig:galaxy}
\end{figure}
\begin{figure}[htp]
    \centering
    \includegraphics[width=10cm]{ST2-2.png}
    \caption{result from mixed identification cont}
    \label{fig:galaxy}
\end{figure}
\subsubsection{Evaluation}
Accrording to figure 1, we can see directly the percentage of precision and recall generated from the regex identification method. Apart from the 4 types that generate a very good result, the rest of the types does not come up with anything.
And according to figure 2 and 3, we can see that by using the dictionary identification method, we can get a good result on the rest of the labels but not for the four labels presented in figure 1. Thus we merge the two together and created a better algorithm for all around types.
By looking at Figure 4 and 5, we can see that the original values of dictionary identification are applied, and the formatted numerical types are better classified and would render better result
In the tables and columns assigned to our team, the number of columns in which each type appears are:
\begin{itemize}
\item {Address}:14
\item {Areas of study}: 13
\item {Borough}: 12
\item {Building Classification}: 5
\item {Car make}: 8
\item {City}: 9
\item {City agency}: 12
\item {Color}: 8
\item {LAT/LON coordinates}: 11
\item {Neighborhood}: 8
\item {Other}: 20
\item {Parks/Playgrounds}: 4
\item {Person name}: 66
\item {Phone Number}: 12
\item {School Levels}: 10
\item {Subjects in school}: 12
\item {Type of location}: 1
\item {Vehicle Type}: 9
\item {Websites}: 9
\item {Zip code}: 9

\end{itemize}

The following is a table containing columns that have multiple types:
\begin{table*}
  \caption{How many columns have values belonging to multipe types}
  \label{tab:commands}
  \begin{tabular}{ccl}
    \toprule
    Table name& Column name& Labels\\
    \midrule
    d3ge-anaz& CORE\_COURSE\_(MS\_CORE\_and\_9-12\_ONLY)& ['Subjects in school', 'Other']\\
    f7qh-bcr5& CORE\_SUBJECT\_& ['Subjects in school', 'Other']\\
    faiq-9dfq& Vehicle\_Color& ['Color', 'Other']\\
    feu5-w2e2& BusinessCity& ['City', 'Street name', 'Parks/Playgrounds', \\
    &&'Person name', 'Zip code', 'Address', 'Other', 'Phone Number']\\
    gez6-674h& COR\_SUBJECT\_& ['Subjects in school', 'Other']\\
    i8ys-e4pm& CORE\_COURSE(9-12\_ONLY)& ['Subjects in school', 'Other']\\
    kz72-dump& CORE\_SUBJECT\_& ['Subjects in school', 'Other']\\
    mrxb-9w9v& BOROUGH\_COMMUNITY& ['LAT/LON coordinates', 'City']\\
    pgtq-ht5f& CORE\_SUBJECT\_& ['Subjects in school', 'Other']\\
  \bottomrule
\end{tabular}
\end{table*}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% below this line is Task3%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Task3: Data Analysis}
In this task, we choose option 3 to complete, we will make full use of the information extracted from the tables to analyse the data and find out the laws hidden behind the data. \\
This task can be split to 3 parts:
\begin{itemize}
    \item Find out 3 most frequent complaint types of every borough
    \item Find out how these complaint types change over time
    \item Analyse the data and find out the reason
\end{itemize}

\subsection{Preparations}
Determine the tables we will use in this task. In this task, we will use the following tables:
\begin{itemize}
    \item '311 Service Requests for 2004'
    \item '311 Service Requests for 2005'
    \item '311 Service Requests for 2006'
    \item '311 Service Requests for 2007'
    \item '311 Service Requests for 2008'
    \item '311 Service Requests for 2009'
    \item '311 Service Requests from 2010 to Present'
\end{itemize}
For every table, we have to observe the whole table and find out 3 most frequent complaint types of every borough.

\subsection{Result}
After filtering the data, the results we can get are shown below: \\
\textbf{2004}
\begin{itemize}
    \item Queens: Water System, 
    \item Brooklyn: Sewer, Traffic Signal Condition, Blocked Driveway
    \item Manhattan: Traffic Signal Condition, Street Light Condition, Taxi Complaint
    \item Bronx: Water System, Sewer, Traffic Signal Condition
    \item Staten Island: Water System, Sewer, Street Light Condition
\end{itemize}
\textbf{2007}
\begin{itemize}
    \item Queens: Sewer, Water System, Blocked Driveway
    \item Brooklyn: Sewer, Traffic Signal Condition, Blocked Driveway
    \item Manhattan: Traffic Signal Condition, Street Light Condition, Taxi Complaint
    \item Bronx: Water System, Sewer, Traffic Signal Condition
    \item Staten Island: Water System, Sewer, Street Light Condition
\end{itemize}

\textbf{2010 - Present}
\begin{itemize}
    \item Queens: Noise - Residential, Street Condition, Street Light Condition
    \item Brooklyn: HEAT/HOT WATER, Blocked Driveway, Illegal Parking
    \item Manhattan: HEAT/HOT WATER, Noise, Noise - Street/Sidewalk
    
\end{itemize}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% end of Task 3%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



\end{document}
\endinput
%%
%% End of file `sample-sigconf.tex'.
